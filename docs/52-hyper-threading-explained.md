# 超线程技术深度解析：每个核心到底有几套寄存器？

## 核心答案

**每个物理核心有几套物理寄存器，取决于CPU架构：**

```
无超线程（传统CPU）：
  1个物理核心 = 1套物理寄存器

有超线程（Intel HT, AMD SMT）：
  1个物理核心 = 2套架构寄存器（可见寄存器）
               + 1套共享执行单元
               + 共享L1/L2缓存

关键理解：
- 架构寄存器（Architectural Registers）：软件可见的寄存器（rax, rbx等）
- 执行单元（Execution Units）：ALU、FPU、加载/存储单元（硬件资源）
- 超线程：2套架构寄存器 + 共享执行单元
```

---

## 1. 超线程（Hyper-Threading）的硬件实现

### 1.1 无超线程的CPU核心

```
传统CPU核心结构：
┌──────────────────────────────────────┐
│ 物理核心 0                            │
│                                      │
│ ┌──────────────────────────────────┐ │
│ │ 架构寄存器（1套）                   │ │
│ │ ┌─────────────┐                  │ │
│ │ │ rax         │                  │ │
│ │ │ rbx         │                  │ │
│ │ │ rcx         │                  │ │
│ │ │ rdx         │                  │ │
│ │ │ rsi, rdi    │                  │ │
│ │ │ r8-r15      │                  │ │
│ │ │ rip, rsp    │                  │ │
│ │ │ xmm0-xmm15  │  (FPU/SSE)       │ │
│ │ └─────────────┘                  │ │
│ └──────────────────────────────────┘ │
│                                      │
│ ┌──────────────────────────────────┐ │
│ │ 执行单元                          │ │
│ │ - 整数ALU (4个)                   │ │
│ │ - 浮点FPU (2个)                   │ │
│ │ - 加载/存储单元 (2个)              │ │
│ │ - 分支预测器                       │ │
│ └──────────────────────────────────┘ │
│                                      │
│ ┌──────────────────────────────────┐ │
│ │ L1 Cache (32KB)                  │ │
│ └──────────────────────────────────┘ │
└──────────────────────────────────────┘

操作系统视图：
  /proc/cpuinfo 显示：1个CPU

状态：
  同一时刻只能运行1个线程
```

### 1.2 有超线程的CPU核心（Intel Hyper-Threading）

```
支持超线程的CPU核心结构：
┌──────────────────────────────────────────────────┐
│ 物理核心 0                                        │
│                                                  │
│ ┌──────────────────────┐  ┌──────────────────┐   │
│ │ 逻辑核心 0            │  │ 逻辑核心 1         │   │
│ │ 架构寄存器（1套）       │  │ 架构寄存器（1套）  │    │
│ │ ┌─────────────┐      │  │ ┌─────────────┐  │   │
│ │ │ rax         │      │  │ │ rax         │  │   │
│ │ │ rbx         │      │  │ │ rbx         │  │   │
│ │ │ rcx         │      │  │ │ rcx         │  │   │
│ │ │ rdx         │      │  │ │ rdx         │  │   │
│ │ │ rsi, rdi    │      │  │ │ rsi, rdi    │  │   │
│ │ │ r8-r15      │      │  │ │ r8-r15      │  │   │
│ │ │ rip, rsp    │      │  │ │ rip, rsp    │  │   │
│ │ │ xmm0-xmm15  │      │  │ │ xmm0-xmm15  │  │   │
│ │ └─────────────┘      │  │ └─────────────┘  │   │
│ └──────────────────────┘  └──────────────────┘   │
│           ↓                        ↓             │
│           └────────────┬───────────┘             │
│                        ↓                         │
│ ┌──────────────────────────────────────────────┐ │
│ │ 共享执行单元（硬件资源）                         │ │
│ │ - 整数ALU (4个) ← 两个线程竞争                  │ │
│ │ - 浮点FPU (2个) ← 两个线程竞争                  │ │
│ │ - 加载/存储单元 (2个) ← 两个线程竞争             │ │
│ │ - 分支预测器 ← 共享                            │ │
│ │ - 重排序缓冲区（ROB）← 分区或共享                │ │
│ └──────────────────────────────────────────────┘ │
│                                                  │
│ ┌──────────────────────────────────────────────┐ │
│ │ L1 Cache (32KB) ← 共享                        │ │
│ └──────────────────────────────────────────────┘ │
└──────────────────────────────────────────────────┘

操作系统视图：
  /proc/cpuinfo 显示：2个CPU（逻辑CPU）

状态：
  同一时刻可以运行2个线程（但共享执行单元）
```

---

## 2. 关键概念辨析

### 2.1 架构寄存器 vs 物理寄存器

```
架构寄存器（Architectural Registers）：
- 软件可见的寄存器（ISA定义）
- 例如：rax, rbx, rcx, rdx, rsi, rdi, r8-r15, rip, rsp
- x86-64有：16个通用寄存器 + 16个SIMD寄存器 + 特殊寄存器
- 超线程：每个逻辑核心有1套独立的架构寄存器

物理寄存器（Physical Registers）：
- CPU内部实际的寄存器（寄存器重命名）
- 数量远多于架构寄存器（通常几百个）
- 用于乱序执行和寄存器重命名
- 超线程：多个逻辑核心共享物理寄存器池

示例（简化）：
┌────────────────────────────────────────┐
│ 架构寄存器（软件视图）                     │
│ 逻辑核心0: rax, rbx, rcx, ...           │
│ 逻辑核心1: rax, rbx, rcx, ...           │
└────────────────────────────────────────┘
              ↓ 映射
┌────────────────────────────────────────┐
│ 物理寄存器池（硬件实现）                   │
│ P0, P1, P2, ..., P223                  │
│ （224个物理寄存器，Intel Skylake）        │
│ 两个逻辑核心共享这个池                     │
└────────────────────────────────────────┘

寄存器重命名：
  逻辑核心0: rax → P45
  逻辑核心1: rax → P87
  （两个rax映射到不同的物理寄存器）
```

### 2.2 执行单元的共享

```
关键理解：超线程不是真正的"双核"

场景1：两个线程都在执行整数运算
┌────────────────────────────────────────┐
│ 整数ALU（4个）                           │
│ ┌────┐ ┌────┐ ┌────┐ ┌────┐            │
│ │ALU0│ │ALU1│ │ALU2│ │ALU3│            │
│ └────┘ └────┘ └────┘ └────┘            │
│   ↑      ↑      ↑      ↑               │
│ 线程0  线程1  线程0  线程1                │
│ （竞争使用！性能提升 < 2倍）               │
└────────────────────────────────────────┘

场景2：线程0等待内存，线程1执行计算
┌────────────────────────────────────────┐
│ 整数ALU（4个）                           │
│ ┌────┐ ┌────┐ ┌────┐ ┌────┐            │
│ │ALU0│ │ALU1│ │ALU2│ │ALU3│            │
│ └────┘ └────┘ └────┘ └────┘            │
│   ↑      ↑      ↑      ↑               │
│ 线程1  线程1  线程1  线程1                │
│ （线程0阻塞，线程1独占！）                 │
│ （这是超线程的最佳场景）                   │
└────────────────────────────────────────┘

性能提升：
- 两个计算密集型线程：+10-20%（竞争执行单元）
- 一个计算 + 一个内存密集：+30-40%（充分利用空闲）
```

---

## 3. 实际CPU架构对比

### 3.1 Intel Core i7-12700K（12代，混合架构）

```
物理核心：12个
├── P-Core（性能核）：8个，支持超线程
│   └── 每个P-Core = 2个逻辑核心
│       ├── 2套架构寄存器
│       ├── 共享执行单元（6个整数ALU + 2个FPU）
│       └── 共享L1/L2缓存
├── E-Core（效率核）：4个，不支持超线程
│   └── 每个E-Core = 1个逻辑核心
│       ├── 1套架构寄存器
│       └── 更少的执行单元

逻辑核心（线程）：20个
├── P-Core贡献：8 × 2 = 16个逻辑核心
└── E-Core贡献：4 × 1 = 4个逻辑核心

缓存：
├── L1：每个核心独立（48KB指令 + 32KB数据）
├── L2：每个P-Core 1.25MB，每4个E-Core共享2MB
└── L3：25MB（所有核心共享）
```

### 3.2 AMD Ryzen 9 7950X（Zen 4架构）

```
物理核心：16个，全部支持SMT（类似超线程）
└── 每个核心 = 2个逻辑核心（SMT）
    ├── 2套架构寄存器
    ├── 共享执行单元（4个整数ALU + 4个FPU）
    └── 共享L1/L2缓存

逻辑核心（线程）：32个
└── 16核心 × 2线程 = 32逻辑核心

缓存：
├── L1：每个核心64KB（32KB指令 + 32KB数据）
├── L2：每个核心1MB（独立）
└── L3：64MB（分为2个CCD，每个32MB）

AMD SMT vs Intel HT：
- 原理相同：1个物理核心，2套架构寄存器，共享执行单元
- AMD叫SMT（Simultaneous Multi-Threading）
- Intel叫HT（Hyper-Threading）
```

### 3.3 Apple M2（ARM架构，不支持SMT）

```
物理核心：8个，不支持SMT/超线程
├── 性能核：4个
│   └── 每个核心 = 1个逻辑核心
│       ├── 1套架构寄存器
│       └── 更多的执行单元（8个整数ALU）
├── 效率核：4个
│   └── 每个核心 = 1个逻辑核心

逻辑核心（线程）：8个
└── 8核心 × 1线程 = 8逻辑核心

为什么不用SMT？
- ARM架构更宽的执行单元（8个ALU vs Intel的6个）
- 更大的物理寄存器文件（允许更多指令并行）
- SMT的收益不大（<10%），不值得增加复杂度
```

---

## 4. 查看CPU的超线程信息

### 4.1 Linux命令

```bash
# 查看CPU信息
$ lscpu
Architecture:        x86_64
CPU(s):              20           ← 逻辑核心总数
Thread(s) per core:  2            ← 每个物理核心2个线程（超线程）
Core(s) per socket:  10           ← 每个CPU 10个物理核心
Socket(s):           1

# 详细信息
$ cat /proc/cpuinfo | grep -E "processor|physical id|core id|cpu cores" | head -20

# 示例输出（Intel i7-12700K，简化）：
processor   : 0    ← 逻辑核心0
physical id : 0    ← 物理CPU 0
core id     : 0    ← 物理核心0
cpu cores   : 12

processor   : 1    ← 逻辑核心1（超线程）
physical id : 0    ← 物理CPU 0
core id     : 0    ← 物理核心0（同一个核心！）
cpu cores   : 12

processor   : 2    ← 逻辑核心2
physical id : 0
core id     : 1    ← 物理核心1
cpu cores   : 12

# 查看超线程是否开启
$ cat /sys/devices/system/cpu/smt/active
1  ← 1表示开启，0表示关闭

# 禁用超线程（临时）
$ echo off | sudo tee /sys/devices/system/cpu/smt/control

# 启用超线程
$ echo on | sudo tee /sys/devices/system/cpu/smt/control
```

### 4.2 拓扑关系

```bash
# 查看CPU拓扑
$ lstopo

# 输出示例（简化）：
Machine (64GB)
  Package L#0
    L3 L#0 (25MB)
      L2 L#0 (1.25MB)
        L1d L#0 (32KB) + L1i L#0 (48KB)
          Core L#0
            PU L#0 (P#0)   ← 逻辑核心0
            PU L#1 (P#1)   ← 逻辑核心1（超线程伙伴）
      L2 L#1 (1.25MB)
        L1d L#1 (32KB) + L1i L#1 (48KB)
          Core L#1
            PU L#2 (P#2)   ← 逻辑核心2
            PU L#3 (P#3)   ← 逻辑核心3（超线程伙伴）
```

---

## 5. 超线程对性能的影响

### 5.1 性能提升场景

```c
// 场景1：内存密集型 + 计算密集型（最佳）

// 线程0：内存密集型（经常cache miss）
void* thread0(void* arg) 
{
    for (int i = 0; i < N; i++) 
    {
        result += huge_array[random_index()];  // Cache miss频繁
    }
}

// 线程1：计算密集型
void* thread1(void* arg) 
{
    for (int i = 0; i < N; i++) 
    {
        result += sqrt(i) * sin(i);  // 纯计算
    }
}

// 如果绑定到同一个物理核心的2个逻辑核心：
// - 线程0 cache miss时，执行单元空闲
// - 线程1利用空闲的执行单元进行计算
// - 性能提升：30-40%

性能对比：
单线程：                 100 tasks/s
双线程无超线程（2个物理核）：200 tasks/s (2倍)
双线程有超线程（1个物理核）：135 tasks/s (1.35倍)
```

### 5.2 性能下降场景

```c
// 场景2：两个计算密集型线程（竞争执行单元）

// 线程0：密集计算
void* thread0(void* arg) 
{
    for (int i = 0; i < N; i++) 
    {
        result += sqrt(i) * sqrt(i+1) * sqrt(i+2);
    }
}

// 线程1：密集计算
void* thread1(void* arg) 
{
    for (int i = 0; i < N; i++) 
    {
        result += sin(i) * cos(i) * tan(i);
    }
}

// 如果绑定到同一个物理核心的2个逻辑核心：
// - 两个线程竞争FPU单元（只有2个）
// - 性能提升有限，甚至可能下降

性能对比：
单线程：                 100 tasks/s
双线程无超线程（2个物理核）：200 tasks/s (2倍)
双线程有超线程（1个物理核）：110 tasks/s (1.1倍，甚至更低)
```

### 5.3 高频交易场景：禁用超线程

```bash
# 为什么高频交易要禁用超线程？

原因1：延迟抖动
- 超线程导致执行单元竞争
- 延迟不可预测（0-100μs抖动）

原因2：缓存污染
- 同一个物理核心的2个线程共享L1/L2缓存
- 一个线程污染另一个线程的缓存

原因3：性能核心绑定
- 高频交易需要独占物理核心
- 不希望有其他线程干扰

配置：
# BIOS禁用超线程
# 或运行时禁用
$ echo off | sudo tee /sys/devices/system/cpu/smt/control

# 验证
$ lscpu | grep "Thread(s) per core"
Thread(s) per core:  1  ← 禁用成功

结果：
- 物理核心数不变（如8个）
- 逻辑核心数减半（从16个变为8个）
- 延迟稳定性提升
- 吞吐量可能下降10-20%（值得，换取低延迟）
```

---

## 6. 上下文切换与超线程

### 6.1 同一物理核心的2个逻辑核心之间切换

```
场景：线程A和线程B都在物理核心0的两个逻辑核心上

┌──────────────────────────────────────┐
│ 物理核心0                             │
│ ┌─────────────┐  ┌─────────────┐     │
│ │ 逻辑核心0    │  │ 逻辑核心1     │     │
│ │ 寄存器组0    │  │ 寄存器组1     │     │
│ │ rax=123     │  │ rax=456     │     │
│ │ rbx=789     │  │ rbx=012     │     │
│ └─────────────┘  └─────────────┘     │
└──────────────────────────────────────┘

如果线程A（逻辑核心0）→ 线程B（逻辑核心1）：
- 不需要保存/恢复寄存器（每个逻辑核心有独立的寄存器）
- 不需要切换页表（同一个物理核心）
- 只需要切换执行单元的调度（硬件自动）

开销：几乎为0！（硬件级切换）

这不是真正的"上下文切换"，而是硬件多线程。
```

### 6.2 不同物理核心之间的切换

```
场景：线程A（核心0，逻辑0）→ 线程B（核心1，逻辑0）

物理核心0                物理核心1
┌─────────────┐        ┌─────────────┐
│ 逻辑核心0    │        │ 逻辑核心0     │
│ rax=123     │        │ rax=456     │
└─────────────┘        └─────────────┘

上下文切换：
1. 保存核心0的寄存器到task_A
2. 恢复核心1的寄存器从task_B
3. 切换页表（如果是不同进程）
4. 缓存污染（核心1的L1/L2被污染）

开销：~3μs + 缓存污染（~10-100μs）

这是真正的上下文切换。
```

---

## 7. 面试回答模板

**问题**："每个核2个线程，是指每个核心有2套物理寄存器吗？

**标准答案**：

"是的，但需要区分两个概念：

**1. 架构寄存器（软件可见）**：
支持超线程的物理核心有2套独立的架构寄存器（rax, rbx, rcx等）。每个逻辑核心一套，这样操作系统可以同时调度2个线程到同一个物理核心上，
它们有各自独立的寄存器状态。

**2. 执行单元（硬件资源）**：
但这2个逻辑核心共享执行单元（ALU、FPU、加载/存储单元）和缓存（L1/L2）。这意味着：
- 同一时刻只能执行1-2条指令（取决于执行单元数量）
- 两个线程竞争有限的执行资源

**关键原理**：
超线程不是真正的"双核"，而是：
- 硬件：1个物理核心
- 软件视图：2个逻辑CPU
- 实现：2套架构寄存器 + 1套共享执行单元

**性能影响**：
- 最佳场景（内存+计算）：+30-40%
- 一般场景（两个计算）：+10-20%
- 最差场景（竞争FPU）：+0-10%，甚至负提升

**高频交易建议**：
通常禁用超线程，因为：
- 避免执行单元竞争导致的延迟抖动
- 避免缓存污染
- 需要可预测的低延迟，而不是最大吞吐量

**验证方法**：
```bash
lscpu | grep 'Thread(s) per core'
# 输出2表示超线程开启，输出1表示关闭
```

---

## 8. OS线程 vs 逻辑核心（超线程）

### 8.1 概念区分（非常重要！）

```
关键理解：OS线程 ≠ 逻辑核心（硬件线程）

硬件层（CPU提供）：
┌─────────────────────────────────────────┐
│ 逻辑核心（Logical Core / Hardware Thread）│
│ - 由超线程技术创建                         │
│ - 数量固定（如20个）                       │
│ - 硬件概念                               │
│ - 每个逻辑核心有独立的架构寄存器             │
└─────────────────────────────────────────┘

操作系统层（OS管理）：
┌────────────────────────────────────────┐
│ OS线程（Software Thread / task_struct） │
│ - 由程序创建（pthread_create等）         │
│ - 数量不限（可以几千个）                  │
│ - 软件概念                              │
│ - 每个OS线程有独立的task_struct结构       │
└────────────────────────────────────────┘

调度关系：
  OS调度器将OS线程调度到逻辑核心上执行
  ↓
  N个OS线程 → 时间片轮转 → M个逻辑核心（N >> M）
```

### 8.2 具体示例

```
硬件配置：Intel i7-12700K（12核20线程）
├── 8个P-Core（性能核），每个支持超线程
│   └── 8 × 2 = 16个逻辑核心
├── 4个E-Core（效率核），不支持超线程
│   └── 4 × 1 = 4个逻辑核心
└── 总计：20个逻辑核心（/proc/cpuinfo显示20个CPU）

操作系统上运行的软件：
├── 进程1：Google Chrome
│   ├── OS线程1（主线程）
│   ├── OS线程2（渲染线程）
│   ├── OS线程3（V8引擎）
│   ├── ...
│   └── OS线程50（网络线程）
├── 进程2：VSCode
│   ├── OS线程1
│   ├── ...
│   └── OS线程30
├── 进程3：数据库服务
│   ├── ...
│   └── OS线程100
└── 总计：可能有1000+个OS线程！

调度关系：
  1000+个OS线程 → 调度器 → 20个逻辑核心
  ↓
  同一时刻，最多20个OS线程在执行（其他在等待）
  每个逻辑核心同一时刻只运行1个OS线程
```

### 8.3 调度过程详解

```c
时间片调度（简化）：

T1时刻：20个逻辑核心的状态
┌────────────────┬──────────────────┐
│ 逻辑核心        │ 正在运行的OS线程    │
├────────────────┼──────────────────┤
│ CPU 0          │ Chrome线程#5      │
│ CPU 1          │ Chrome线程#7      │ ← 同一个物理核心的两个逻辑核心
│ CPU 2          │ VSCode线程#2      │
│ CPU 3          │ VSCode线程#8      │
│ ...            │ ...              │
│ CPU 19         │ DB线程#42         │
└────────────────┴──────────────────┘

等待队列（就绪状态）：
├── Chrome线程#1, #2, #3, ... (45个)
├── VSCode线程#3, #4, ... (28个)
├── DB线程#1, #3, ... (98个)
└── 其他800+个OS线程

T2时刻（时间片到期，10ms后）：
┌────────────────┬──────────────────┐
│ 逻辑核心        │ 正在运行的OS线程    │
├────────────────┼──────────────────┤
│ CPU 0          │ VSCode线程#3      │ ← 切换了！
│ CPU 1          │ Chrome线程#7      │ ← 未切换（时间片未到）
│ CPU 2          │ DB线程#1          │ ← 切换了！
│ CPU 3          │ VSCode线程#8      │ ← 未切换
│ ...            │ ...              │
│ CPU 19         │ Chrome线程#2      │ ← 切换了！
└────────────────┴──────────────────┘

关键理解：
1. 逻辑核心数量固定（20个）
2. OS线程数量动态（可能1000+个）
3. 调度器通过上下文切换，让OS线程轮流使用逻辑核心
4. 超线程只影响逻辑核心数量，不影响OS线程的创建和调度
```

### 8.4 常见误区

```
误区1："8核16线程CPU可以同时运行16个程序"
正确理解：
   - 可以同时运行16个OS线程（每个逻辑核心1个）
   - 但系统可能有几千个OS线程在时间片轮转
   - 每个程序（进程）可能有多个OS线程

误区2："超线程就是操作系统创建的线程"
正确理解：
   - 超线程是硬件技术（CPU层面）
   - OS线程是软件概念（操作系统层面）
   - 超线程提供更多逻辑核心，让OS可以调度更多线程并发执行

误区3："1个OS线程对应1个逻辑核心"
正确理解：
   - N个OS线程 → M个逻辑核心（N通常 >> M）
   - 通过时间片轮转，多个OS线程共享1个逻辑核心
   - 例如：1000个OS线程 → 20个逻辑核心

误区4："创建100个OS线程，在20核CPU上可以全部并发"
正确理解：
   - 最多20个OS线程真正并发（物理限制）
   - 其他80个在等待队列中
   - 通过上下文切换快速轮转，看起来"并发"
```

### 8.5 验证实验

```c
#include <pthread.h>
#include <stdio.h>
#include <unistd.h>
#include <sched.h>

void* thread_func(void* arg) 
{
    int tid = *(int*)arg;

    // 获取当前运行的CPU（逻辑核心）
    int cpu = sched_getcpu();
    printf("OS线程 %d 正在逻辑核心 %d 上运行\n", tid, cpu);

    // 运行一段时间
    sleep(100);

    return NULL;
}

int main() 
{
    pthread_t threads[100];
    int tids[100];

    // 创建100个OS线程
    for (int i = 0; i < 100; i++) 
    {
        tids[i] = i;
        pthread_create(&threads[i], NULL, thread_func, &tids[i]);
    }

    // 等待所有线程
    for (int i = 0; i < 100; i++) 
    {
        pthread_join(threads[i], NULL);
    }

    return 0;
}

// 编译运行：
// $ gcc -pthread thread_test.c -o thread_test
// $ ./thread_test

// 输出示例（20个逻辑核心的系统）：
// OS线程 0 正在逻辑核心 3 上运行
// OS线程 1 正在逻辑核心 7 上运行
// OS线程 2 正在逻辑核心 2 上运行
// ...
// OS线程 19 正在逻辑核心 15 上运行
// OS线程 20 正在逻辑核心 0 上运行  ← 复用！
// OS线程 21 正在逻辑核心 4 上运行  ← 复用！
// ...

// 观察：
// 1. 创建了100个OS线程（软件概念）
// 2. 但只有20个逻辑核心（硬件限制）
// 3. 多个OS线程会被调度到同一个逻辑核心（通过时间片轮转）

// 查看线程分布：
$ ps -eLo pid,tid,psr,comm | grep thread_test
# PSR列显示当前运行在哪个CPU（逻辑核心）
```

### 8.6 实际应用：线程池设计

```c
// 问题：线程池应该创建多少个OS线程？

// 错误做法：创建与逻辑核心数相同的线程
int num_threads = sysconf(_SC_NPROCESSORS_ONLN);  // 20
// 问题：如果任务涉及I/O阻塞，20个线程不够用

// 正确做法：根据任务类型调整
int num_cores = sysconf(_SC_NPROCESSORS_ONLN);

if (is_cpu_bound) 
{
    // CPU密集型：线程数 = 核心数（或核心数+1）
    num_threads = num_cores;
} 
else if (is_io_bound) 
{
    // I/O密集型：线程数 = 核心数 × (1 + 阻塞时间/计算时间)
    // 例如：阻塞时间占90% → 20 × (1 + 9) = 200个线程
    num_threads = num_cores * 10;
} 
else 
{
    // 混合型：根据实测调优
    num_threads = num_cores * 2;
}

// 高频交易场景：
// 1. 禁用超线程：20逻辑核心 → 10物理核心
// 2. 每个关键任务绑定1个物理核心（独占）
// 3. 不使用线程池（延迟不可预测）
```

---

## 9. 总结对比表

| 特性          | 无超线程    | 有超线程（HT/SMT）  |
|-------------|---------|---------------|
| **架构寄存器**   | 1套/核心   | 2套/核心         |
| **执行单元**    | 1套/核心   | 1套/核心（共享）     |
| **L1/L2缓存** | 1套/核心   | 1套/核心（共享）     |
| **逻辑CPU数**  | = 物理核心数 | = 物理核心数 × 2   |
| **并行线程数**   | 1/核心    | 2/核心（竞争资源）    |
| **性能提升**    | N/A     | +10-40%（场景依赖） |
| **延迟抖动**    | 低       | 中（竞争导致）       |
| **适用场景**    | 低延迟     | 高吞吐量          |

**关键洞察**：
超线程通过在同一物理核心上维护2套架构寄存器，让OS可以调度2个线程，利用一个线程等待时的空闲执行单元。这不是真正的"双倍性能"，而是提高资源利用率的技术。
